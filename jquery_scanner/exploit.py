import sys
import requests
from requests.packages.urllib3.exceptions import InsecureRequestWarning
requests.packages.urllib3.disable_warnings(InsecureRequestWarning)

class colors:
        red  ='\033[91m'
        green='\033[92m'
        blue ='\033[94m'
        reset='\033[0m'


def show_msg(status,url,http_code,http_body):
    msg=''
    n=0
    unit='B'
    if len(http_body)>(1024*1024):
        unit='MB'
        n=len(http_body)/(1024*1024)
    elif len(http_body)>1024:
        unit='KB'
        n=len(http_body)/(1024)

    if status == 'fail':
        msg=f'{colors.red}[-] '
        msg+=f'{url}{colors.reset}'
    if status == 'susses':
        msg=f'{colors.green}[+] '
        msg+=f'{url} [{http_code}] - {n:.2f}{unit}{colors.reset}'
    return msg


def brute_scan(url:str):
    with open('version_list.txt', 'r') as f:
        versions = f.read().split('\n')

    for ver in versions:
        tmp=url.replace('<VERSION_SCAN>',ver)
        res=requests.get(tmp,verify=False)
        if res.status_code==200:
            print(show_msg('susses',tmp,res.status_code,res.text))
        else:
            print(show_msg('fail',tmp,res.status_code,res.text))


def version_crawl(url:str):

    date_of_version={
        '* $Date: 2006-10-27 23:14:48':'1.0.1',
        '* $Date: 2006-10-09 21:59:20':'1.0.2',
        '* $Date: 2006-10-27 11:15:44':'1.0.3',
        '* $Date: 2006-12-12 15:33:10':'1.0.4',
        '* $Date: 2007-01-14 17:37:33':'1.1',
        '* $Date: 2007-01-22 00:27:54':'1.1.1',
        '* $Date: 2007-02-28 12:03:00':'1.1.2',
        '* $Date: 2007-07-01 08:54:38':'1.1.3',
        '* $Date: 2007-08-23 21:49:27':'1.1.4',
        '* $Date: 2007-09-10 15:45:49':'1.2',
        '* $Date: 2007-09-16 23:42:06':'1.2.1',
        '* $Date: 2008-01-14 17:56:07':'1.2.2',
        '* $Date: 2008-02-06 00:21:25':'1.2.3',
        '* $Date: 2008-05-18 23:05:38':'1.2.4',
        '* $Date: 2008-05-20 23:14:54':'1.2.5',
        '* $Date: 2008-05-24 14:22:17':'1.2.6',
        '* Date: 2009-01-13 12:50:31':'1.3',
        '* Date: 2009-01-21 20:42:16':'1.3.1',
        '* Date: 2009-02-19 17:34:21':'1.3.2',
        '* Date: Wed Jan 13 15:23:05':'1.4',
        '* Date: Mon Jan 25 19:43:33':'1.4.1',
        '* Date: Sat Feb 13 22:33:48':'1.4.2',
        '* Date: Thu Oct 14 23:10:06':'1.4.3',
        '* Date: Thu Nov 11 19:04:53':'1.4.4',
        '* Date: Mon Jan 31 08:31:29':'1.5',
        '* Date: Wed Feb 23 13:55:29':'1.5.1',
        '* Date: Thu Mar 31 15:28:23':'1.5.2',
        '* Date: Mon May 2 13:50:00':'1.6',
        '* Date: Thu May 12 15:04:36':'1.6.1',
        '* Date: Thu Jun 30 14:16:56':'1.6.2',
        '* Date: Wed Aug 31 10:35:15':'1.6.3',
        '* Date: Mon Sep 12 18:54:48':'1.6.4',
        '* Date: Thu Nov 3 16:18:21':'1.7.0',
        '* Date: Mon Nov 21 21:11:03':'1.7.1',
        '* Date: Wed Mar 21 12:46:34':'1.7.2',
        '* Date: Thu Aug 09 2012 16:24:48':'1.8.0',
        '* Date: Thu Aug 30 2012 17:17:22':'1.8.1',
        '* Date: Thu Sep 20 2012 21:13:05':'1.8.2',
        '* Date: Tue Nov 13 2012 08:20:33':'1.8.3',
        '* Date: 2013-1-14':'1.9.0',
        '* Date: 2013-2-4':'1.9.1',
        '* Date: 2013-05-24T18:39Z':'1.10.0',
        '* Date: 2013-05-30T21:49Z':'1.10.1',
        '* Date: 2013-07-03T13:48Z':'1.10.2',
        '* Date: 2014-01-23T21:02Z':'1.11.0',
        '* Date: 2014-05-01T17:42Z':'1.11.1',
        '* Date: 2014-12-17T15:27Z':'1.11.2',
        '* Date: 2015-04-28T16:19Z':'1.11.3',
        '* Date: 2016-01-08T19:56Z':'1.12.0',
        '* Date: 2016-02-22T19:07Z':'1.12.1',
        '* Date: 2016-03-17T17:44Z':'1.12.2',
        '* Date: 2016-04-05T19:16Z':'1.12.3',
        '* Date: 2016-05-20T17:17Z':'1.12.4',
        '* Date: 2013-04-18':'2.0.0',
        '* Date: 2013-05-24T16:44Z':'2.0.1',
        '* Date: 2013-05-30T21:25Z':'2.0.2',
        '* Date: 2013-07-03T13:30Z':'2.0.3',
        '* Date: 2014-01-23T21:10Z':'2.1.0',
        '* Date: 2014-05-01T17:11Z':'2.1.1',
        '* Date: 2014-12-17T14:01Z':'2.1.2',
        '* Date: 2014-12-18T15:11Z':'2.1.3',
        '* Date: 2015-04-28T16:01Z':'2.1.4',
        '* Date: 2016-01-08T20:02Z':'2.2.0',
        '* Date: 2016-02-22T19:11Z':'2.2.1',
        '* Date: 2016-03-17T17:51Z':'2.2.2',
        '* Date: 2016-04-05T19:26Z':'2.2.3',
        '* Date: 2016-05-20T17:23Z':'2.2.4',
        '* Date: 2016-06-09T18:02Z':'3.0.0',
        '* Date: 2016-07-07T21:44Z':'3.1.0',
        '* Date: 2016-09-22T22:30Z':'3.1.1',
        '* Date: 2017-03-16T21:26Z':'3.2.0',
        '* Date: 2017-03-20T18:59Z':'3.2.1',
        '* Date: 2018-01-19T19:00Z':'3.3.0',
        '* Date: 2018-01-20T17:24Z':'3.3.1',
        '* Date: 2019-04-10T19:48Z':'3.4.0',
        '* Date: 2019-05-01T21:04Z':'3.4.1',
        '* Date: 2020-04-10T15:07Z':'3.5.0',
        '* Date: 2020-05-04T22:49Z':'3.5.1',
        '* Date: 2021-03-02T17:08Z':'3.6.0',
        '* Date: 2022-08-26T17:52Z':'3.6.1',
        '* Date: 2022-12-13T14:56Z':'3.6.2',
        '* Date: 2022-12-20T21:28Z':'3.6.3',
        '* Date: 2023-03-08T15:28Z':'3.6.4',
        '* Date: 2023-05-11T18:29Z':'3.7.0',
        '* Date: 2023-08-28T13:37Z':'3.7.1'
    }

    

    with open('version_list.txt', 'r') as f:
        versions = f.read().split('\n')

    res=requests.get(url,verify=False)

    find_ver=[]

    for d,v in date_of_version.items():
        if d in res.text:
            find_ver=date_of_version[d]
    if find_ver:
        print(find_ver)
        return
    
    
    for ver in versions:
        if ver in res.text:
            find_ver.append(ver)

    if find_ver:
        print(find_ver)
    else:
        print('Nonthing :(')

# python3 exploit.py "https://code.jquery.com/jquery-<VERSION_SCAN>.min.js"
def main(param):
    if len(param)<2:
        print(f'python {param[0]} "https://target.com/js/jquery-<VERSION_SCAN>.min.js"')
        print(f'python {param[0]} "https://target.com/js/jquery.min.js"')
        exit(0)
    url=param[1]
    if '<VERSION_SCAN>' in url:
        brute_scan(url)
    else:
        version_crawl(url)

if __name__ == '__main__':
    main(sys.argv)